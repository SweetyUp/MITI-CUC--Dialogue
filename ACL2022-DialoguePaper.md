### 1. A Model-agnostic Data Manipulation Method for Persona-based Dialogue Generation

**论文题目：**[一种独立于模型的个性化对话生成数据处理方法](https://arxiv.org/abs/2204.09867)

**论文链接：**https://arxiv.org/pdf/2204.09867.pdf

**github：**https://github.com/caoyu-noob/d3**

**视频讲解：**【论文分享 | ACL-22 | 一种与模型无关的数据操作方法，用于基于角色的对话生成】 https://www.bilibili.com/video/BV1JB4y1s7Lw/?share_source=copy_web&vd_source=fea62284e5970b3d62018fa7a93f326f

**摘要：**

为了建立智能对话代理，人们对在生成模型中引入明确的角色越来越感兴趣。然而，由于手头基于角色的对话数据有限，可能很难很好地训练对话生成模型。我们指出，这个生成任务的数据挑战在于两个方面：第一，扩大目前基于角色的对话数据集的成本很高；第二，这个任务中的每个数据样本的学习都比传统的对话数据要复杂。为了缓解上述数据问题，我们提出了一种数据处理方法，这种方法与模型无关，可以与任何基于角色的对话生成模型打包，以提高其性能。首先，原始训练样本将被提炼出来，从而有望更容易被拟合。接下来，我们展示了各种有效的方法，可以使这种数据更容易提炼地多样化。然后，一个给定的基础模型将通过构建的数据课程进行训练，即首先在增强的蒸馏样本上，然后在原始样本上。基于基础对话模型（Transformer encoderdecoder和GPT2）的实验证明了我们的优越性。

### 2. A Taxonomy of Empathetic Questions in Social Dialogs

**论文题目：**[社会对话中移情问题的分类](https://aclanthology.org/2022.acl-long.211/)

**论文链接：**https://aclanthology.org/2022.acl-long.211.pdf

**github：**https://paperswithcode.com/paper/?acl=2022.acl-long.211

**摘要：**

有效的提问是成功的对话式聊天机器人的一个重要组成部分。它可以帮助机器人表现出同理心，并通过表现出对说话者情绪的关注而使互动更有吸引力。然而，由于缺乏问题的分类及其在社交聊天中的目的，目前的对话生成方法并没有模拟这种微妙的情绪调节技术。为了解决这个问题，我们开发了一个移情问题分类法（EQT），特别关注问题捕捉交际行为的能力及其情绪调节的意图。我们进一步设计了一个众包任务，用既定的标签对EmpatheticDialogues数据集的一个大型子集进行注释。我们使用人群注释的数据来开发自动标签工具，并为整个数据集制作标签。最后，我们采用信息可视化技术来总结提问行为和意图的共同出现，以及它们在调节对话者的情绪方面的作用。这些结果揭示了社会对话中重要的提问策略。EQT分类方案可以促进对数据集中的问题的计算分析。更重要的是，它可以为未来使用神经或混合方法生成移情问题的努力提供参考。

### 3. Achieving Conversational Goals with Unsupervised Post-hoc Knowledge Injection

**论文题目：**[通过无监督的post-hoc知识融入实现对话目标](https://aclanthology.org/2022.acl-long.224/)

**论文链接：**https://aclanthology.org/2022.acl-long.224.pdf

**github：**https://github.com/majumderb/poki

**摘要：**

目前的神经对话模型的一个局限性是，它们往往在生成的反应中缺乏特异性和信息性，这主要是由于对涵盖有限种类的场景和传达有限知识的训练数据的依赖。缓解这一问题的方法之一是在解码时从外部来源提取相关知识，并将其纳入对话回应中。在本文中，我们提出了一种事后知识注入技术，首先根据对话历史和现有对话模型的初始响应，检索出一组不同的相关知识片段。我们构建多个候选回应，使用基于梯度的解码方法将每个检索到的片段单独注入初始回应，然后通过无监督的排名步骤选择最终回应。我们在以目标为导向的和以知识为基础的对话环境中的实验表明，与先前的对话系统的响应相比，人类注释者判断所提出的方法的输出更有吸引力和信息量。我们进一步表明，在这两个实验环境中，知识增强促进了对话目标的成功实现。

### 4. Achieving Reliable Human Assessment of Open-Domain Dialogue Systems

**论文题目：**[实现对开放领域对话系统的可靠的人类评估](https://aclanthology.org/2022.acl-long.224/)

**论文链接：**https://aclanthology.org/2022.acl-long.445.pdf

**github：**https://github.com/tianboji/dialogue-eval

**摘要：**

本文研究了任务型对话系统的可解释性问题。以前，大多数基于神经的面向任务的对话系统都采用隐式推理使模型预测对人类难以解释的策略。为了获得透明的推理过程，我们引入神经符号来执行显式推理。通过推理链证明模型决策的合理性。由于推导推理链需要对面向任务的对话进行多跳推理，现有的神经符号方法会由于一个阶段而导致错误传播。设计为了克服这一点，我们提出了一种两阶段的方法，包括一个假设发电机和推理机。我们首先获得多个假设，即：通过假设生成器执行期望的任务。然后验证每个假设通过推理器，并选择有效的以进行最终预测。整个系统通过利用原始文本对话而不使用任何推理链注释来训练。对两个公众的实验研究基准数据集表明，所提出的方法不仅获得了更好的结果，而且还引入了一个可解释的决策。

### 5. An Interpretable Neuro-Symbolic Reasoning Framework for Task-Oriented Dialogue Generation

**论文题目：**[一种面向任务的对话生成的可解释神经符号推理框架](https://aclanthology.org/2022.acl-long.338/)

**论文链接：**https://aclanthology.org/2022.acl-long.338.pdf

**github：**https://github.com/shiquanyang/NS-Dial.

**摘要：**

我们在本文中研究了面向任务的对话系统的可解释性问题。以前，大多数基于神经的面向任务的对话系统采用隐性推理策略，使得模型的预测无法被人类解释。为了获得一个透明的推理过程，我们引入了神经符号来进行显式推理，通过推理链来证明模型的决定。由于推理链的推导需要对面向任务的对话进行多跳推理，现有的神经符号方法会因为单阶段设计而引起错误传播。为了克服这个问题，我们提出了一个两阶段的方法，包括一个假设发生器和一个推理器。我们首先通过假说生成器获得多个假说，即执行所需任务的潜在操作。然后，每个假设被推理器验证，并选择有效的假设来进行最终的预测。整个系统通过利用原始文本对话进行训练，不使用任何推理链注释。对两个公共基准数据集的实验研究表明，所提出的方法不仅取得了更好的结果，而且还引入了一个可解释的决策过程。

### 6. Beyond Goldfish Memory: Long-Term Open-Domain Conversation

**论文题目：超越鱼的记忆：长期的开放域对话**

**论文链接：**https://aclanthology.org/2022.acl-long.356.pdf

**github：**

**摘要：**

尽管最近在开放域对话模型方面有所改进，但最先进的模型是在几乎没有背景的短对话中进行训练和评估的。相比之下，长期对话环境几乎没有被研究过。在这项工作中，我们收集并发布了一个人与人之间的数据集，该数据集由多个聊天会话组成，说话的伙伴通过这些会话了解对方的兴趣，并讨论他们从过去会话中所学到的东西。我们展示了在现有数据集上训练的现有模型在这种长期对话环境中的自动和人工评估中表现不佳，我们研究了可以表现得更好的长语境模型。特别是，我们发现检索增强的方法和具有总结和回忆以前对话能力的方法比目前被认为是最先进的标准编码器-解码器架构要好。

本文的主要贡献之一就是收集并发布了 Multi-Session Chat 数据集，用于后续研究。

数据集由一系列episode构成，每个episode包括3~4个sesssion，构造方式如下：

- session 1: 使用PersonaChat数据集。

- session 2/3/4: 假设距session 1已经过去了1 ~ 7小时或 1 ~ 7天，然后两人再次进行对话 (reengage)。worker被要求与另一个worker聊6轮，且要考虑到在之前session中聊天的内容，就是说不仅要考虑自己当前的人设，也要考虑之前两人交互的细节。

### 7. Beyond the Granularity: Multi-Perspective Dialogue Collaborative Selection for Dialogue State Tracking

**论文题目：**[超越细粒度：多视角对话协作选择的对话状态追踪](https://aclanthology.org/2022.acl-long.165/)

**论文链接：**https://aclanthology.org/2022.acl-long.165.pdf

**github：**https://github.com/guojinyu88/dicos-master

**摘要：**

在对话状态跟踪中，对话历史是一个重要的材料，不同的模型对它的利用是不同的。然而，无论对话历史如何使用，在整个状态跟踪过程中，每个现有的模型都会使用自己一致的对话历史，无论哪个槽被更新。显然，它需要不同的对话历史在不同的回合中更新不同的槽位。因此，使用一致的对话内容可能会导致不同槽位的信息不足或冗余，从而影响整体性能。为了解决这个问题，我们设计了DiCoS-DST来动态地选择对应于每个槽的相关对话内容进行状态更新。具体来说，它首先检索对话历史中的回合级话语，并从三个角度组合评估它们与槽的相关性：（1）它与槽名的明确联系；（2）它与当前回合对话的相关性；（3）隐式提及导向推理。然后，这些角度被结合起来产生一个决定，只有被选中的对话内容被送入状态生成器，它明确地将传递给下游状态预测的干扰信息最小化。实验结果表明，我们的方法在MultiWOZ 2.1和MultiWOZ 2.2上取得了新的最先进的性能，并在多个主流基准数据集（包括Sim-M、Sim-R和DSTC2）上取得了卓越的性能。

### 8. CASPI Causal-aware Safe Policy Improvement for Task-oriented Dialogue

**论文题目：** **[CASPI 面向任务的对话的因果感知的安全政策改进](https://ui.adsabs.harvard.edu/abs/2021arXiv210306370S/abstract)

**论文链接：** **https://arxiv.org/pdf/2103.06370.pdf

**github：**

**摘要：**

强化学习在解决复杂任务中最近的成功(RL)最常归因于其探索和开发环境的能力，在那里它已经被训练。采样效率通常不是问题，因为廉价的模拟器可以对策略上的数据进行采样。另一方面，面向任务的对话通常是从使用人类演示收集的离线数据中学习的。收集不同的样本并对它们进行注释是非常昂贵的。不幸的是，在非策略数据上训练的RL方法的使用容易产生偏见和泛化问题，而人类反应的随机性和对话管理系统的非马尔科夫信念状态进一步加剧了这些问题。为此，我们提出了任务导向对话政策学习的批处理RL框架:因果意识安全政策改进(CASPI)。这种方法保证了对话政策的效果，也学会了根据人类反应背后的意图来塑造奖励，而不仅仅是模拟演示数据;这个与batch-RL的结合总体上帮助提高了框架的样本效率。依托Multiwoz2.0数据集，基于生成和端到端的对话任务，我们在对话-上下文-文本的框架上演示了该框架的有效性。在这两种情况下，所提议的方法在这些指标上都优于当前的技术状态。在端到端情况下，我们的方法只训练了10%的数据，能够在四个评估指标中的三个超越当前状态。

### 9. ChatMatch: Evaluating Chatbots by Autonomous Chat Tournaments

**论文题目：**[ChatMatch: 通过自主的聊天锦标赛评估聊天机器人](https://aclanthology.org/2022.acl-long.522/)

**论文链接：**https://aclanthology.org/2022.acl-long.522.pdf

**github：**https://github.com/ruolanyang/chatmatch

**摘要：**

现有的聊天机器人自动评估系统大多依靠静态聊天脚本作为基础事实，这很难获得，并且需要访问机器人的模型作为一种 "白盒测试"。交互式评估缓解了这个问题，但需要人类的参与。在我们的工作中，我们提出了一个互动的聊天机器人评估框架，其中聊天机器人像体育比赛一样相互竞争，使用灵活的评分标准。这个框架可以有效地对聊天机器人进行排名，不受它们的模型结构和它们被训练的领域的影响。

### 10. CICERO: A Dataset for Contextualized Commonsense Inference in Dialogues

**论文题目：**[CICERO：对话中的语境化常识推理数据集](https://aclanthology.org/2022.acl-long.344/)

**论文链接：**https://aclanthology.org/2022.acl-long.344.pdf

**github：**https://github.com/declare-lab/CICERO

**摘要：**

本文讨论了带有语境化常识推理的对话推理问题。我们策划了CICERO，这是一个包含五种基于语料级推理的推理的双人对话数据集：原因、后续事件、前提条件、动机和情感反应。该数据集包含来自5672个对话的53105个此类推理。我们使用这个数据集来解决相关的生成和辨别任务：生成原因和后续事件；生成前提条件、动机和听众的情绪反应；以及选择合理的替代方案。我们的结果确定了这种以对话为中心的常识性知识数据集的价值。我们希望CICERO能够为基于常识的对话推理开辟新的研究途径。

### 11. Contextual Fine-to-Coarse Distillation for Coarse-grained Response Selection in Open-Domain Conversations

**论文题目：**[在开放领域的对话中，对粗粒度的反应选择进行上下文的细化提炼](https://aclanthology.org/2022.acl-long.334/)

**论文链接：**https://aclanthology.org/2022.acl-long.334.pdf

**github：**https://github.com/lemuria-wchen/CFC

**摘要：**

我们研究了基于检索的对话系统中的粗粒度的反应选择问题。这个问题与细粒度的反应选择同样重要，但在现有文献中探讨得较少。在本文中，我们提出了一个上下文细化到粗化（CFC）的提炼模型，用于开放领域对话中的粗粒度响应选择。在我们的CFC模型中，查询、候选语境和响应的密集表征是在多塔结构的基础上使用语境匹配来学习的，从一塔结构（细粒度）中学习到的更丰富的知识被提炼到多塔结构（粗粒度）中以提高检索器的性能。为了评估所提出的模型的性能，我们在Reddit评论库和Twitter语料库的基础上构建了两个新的数据集。在这两个数据集上的大量实验结果表明，与传统的基线方法相比，所提出的方法在所有评价指标上都取得了巨大的改进。

### 12. Continual Prompt Tuning for Dialog State Tracking

**论文题目：**[对话状态跟踪的持续提示调整](https://aclanthology.org/2022.acl-long.80/)

**论文链接：**https://aclanthology.org/2022.acl-long.80v2.pdf

**github：**https://github.com/thu-coai/cpt4dst

**摘要：**

一个理想的对话系统应该能够不断地学习新技能而不忘记旧技能，从而适应其生命周期中的新领域或新任务。然而，不断地训练一个模型往往会导致一个众所周知的灾难性遗忘问题。在本文中，我们提出了 "持续提示调整"，这是一个参数高效的框架，不仅可以避免遗忘，还可以实现任务之间的知识转移。为了避免遗忘，我们在冻结骨干预训练模型的同时，只为每个任务学习和存储几个提示标记的嵌入物。为了实现任务间的双向知识转移，我们提出了几种技术（持续提示初始化、查询融合和记忆重放）来转移前一任务的知识，以及一种记忆引导技术来转移后续任务的知识。广泛的实验表明，与最先进的基线相比，我们提出的关于对话状态跟踪的持续学习方法是有效和高效的。

### 13. DEAM: Dialogue Coherence Evaluation using AMR-based Semantic Manipulations

**论文题目：**[DEAM：使用基于AMR的语义操纵的对话一致性评估](https://aclanthology.org/2022.acl-long.57/)

**论文链接：**https://aclanthology.org/2022.acl-long.57.pdf

**github：**https://github.com/pluslabnlp/deam

**摘要：**

自动评估指标对于开放域对话系统的快速发展至关重要，因为它们有助于超参数调整和模型之间的比较。尽管最近提出的可训练的对话级指标显示了令人鼓舞的结果，但指标的质量在很大程度上取决于训练数据的质量。之前的工作主要借助于启发式文本层面的操作（如语篇洗牌），从连贯的对话（正面例子）中引导出不连贯的对话（负面例子）。这种方法不足以适当地反映高级对话模型和人类之间的互动中出现的不连贯性。为了解决这个问题，我们提出了DEAM，一个对话一致性评价指标，它依靠抽象意义表征（AMR）来应用语义层面的操纵来生成不连贯的（负面）数据。AMR自然有利于在语义层面上注入各种类型的不连贯性来源，如核心推理不一致、不相关、矛盾和减少参与，从而产生更自然的不连贯性样本。我们的实验表明，与基线方法相比，DEAM在几个对话数据集上实现了更高的人类判断的相关性，而且幅度很大。我们还表明，DEAM可以区分由基线操作产生的连贯和不连贯的对话，而那些基线模型不能检测到由DEAM产生的不连贯的例子。我们的结果证明了基于AMR的语义操作在自然负面例子生成方面的潜力。

### 14. DialogVED: A Pre-trained Latent Variable Encoder-Decoder Model for Dialog Response Generation

**论文题目：**[DialogVED: 预先训练好的用于对话响应生成的潜变量编码器-解码器模型](https://aclanthology.org/2022.acl-long.333/)

**论文链接：**https://aclanthology.org/2022.acl-long.333.pdf

**github：**https://github.com/lemuria-wchen/DialogVED

**摘要：**

开放领域的对话响应生成是一个重要的研究课题，其中主要的挑战是生成相关和多样化的响应。在本文中，我们提出了一个新的对话预训练框架，称为DialogVED，它将连续的潜在变量引入到增强的编码器-解码器预训练框架中，以提高反应的相关性和多样性。在大型对话语料库（Reddit）的帮助下，我们使用以下4个任务对模型进行预训练，这些任务在训练语言模型（LMs）和变异自动编码器（VAEs）的文献中使用。1）屏蔽语言模型；2）反应生成；3）词包预测；以及4）KL发散降低。我们还增加了额外的参数来模拟对话中的转向结构，以提高预训练模型的性能。我们在PersonaChat、DailyDialog和DSTC7-AVSD基准上进行了响应生成的实验。实验结果表明，我们的模型在所有这些数据集上都达到了新的最先进的结果。

### 15. Dynamic Schema Graph Fusion Network for Multi-Domain Dialogue State Tracking

**论文题目：**[用于多域对话状态跟踪的动态模式图融合网络](https://arxiv.org/abs/2204.06677)

**论文链接：**https://arxiv.org/pdf/2204.06677v1.pdf

**github：**https://github.com/sweetalyssum/DSGFNet

**摘要：**

对话状态跟踪（DST）旨在跟踪用户在对话过程中的意图。在DST中，对域和时隙之间的关系建模仍然是一个尚未研究的问题。考虑了这种关系的现有方法通常在以下方面存在不足：（1）明确地融合先前的时隙域成员关系和对话感知的动态时隙关系，以及（2）将其推广到不可见的域。为了解决这些问题，我们提出了一种新的动态模式图融合网络（DSGFNet），它生成一个动态模式图，以显式融合先前的时隙域成员关系和对话感知的动态时隙关系。它还使用图式促进知识转移到新领域。DSGFNet由对话话语编码器、模式图编码器、对话感知模式图进化网络和模式图增强的对话状态解码器组成。基准数据集（即SGD、MultiWOZ2.1和MultiWOZ2.2）的经验结果表明，DSGFNet优于现有方法。

### 16. GlobalWoZ: Globalizing MultiWoZ to Develop Multilingual Task-Oriented Dialogue Systems

**论文题目：**[GlobalWoZ：全球化MultiWoz开发面向任务的多语言对话系统](https://arxiv.org/abs/2110.07679)

**论文链接：**https://arxiv.org/pdf/2110.07679.pdf

**github：**https://ntunlpsg.github.io/project/globalwoz/

**摘要：**

在过去的几年中，多语言任务导向对话（ToD）系统的数据收集已经开始发展，该系统可以为使用不同语言的人提供服务。然而，现有的多语种ToD数据集要么由于数据管理成本高昂而对语言的覆盖范围有限，要么忽略了对话实体在使用这些语言的国家几乎不存在的事实。为了解决这些局限性，我们引入了一种新的数据管理方法，该方法可以生成GlobalWoZ——一个大规模的多语言ToD数据集，该数据集是从英语ToD数据集中全球化而来的，用于三个未开发的多语种ToD系统用例。我们的方法是翻译对话模板，并用目标语言国家的当地实体填充。此外，我们将目标语言的覆盖范围扩展到20种语言。我们将发布我们的数据集和一组强大的基线，以鼓励针对真实用例的多语言ToD系统的研究。

### 17. HeterMPC: A Heterogeneous Graph Neural Network for Response Generation in Multi-Party Conversations

**论文题目：**[HeterMPC：一种用于多方对话响应生成的异构图神经网络](https://arxiv.org/abs/2203.08500)

**论文链接：**https://arxiv.org/pdf/2203.08500v1.pdf

**github：**https://github.com/lxchtan/HeterMPC

**摘要：**

最近，针对双方对话的各种响应生成模型已经取得了令人印象深刻的改进，但对更实际、更复杂的多方对话（MPC）的关注较少。与对话语境是话语序列的两方对话相比，为MPC构建响应生成模型更具挑战性，因为存在复杂的语境结构，生成的响应严重依赖于对话者（即说话人和受话人）和历史话语。为了应对这些挑战，我们提出了HeterMPC，这是一种基于异构图的神经网络，用于MPC中的响应生成，它使用图中的两种节点同时对话语和对话者的语义进行建模。此外，我们还设计了六种具有节点边缘类型依赖参数的元关系来表征图中的异质交互。通过多跳更新，HeterMPC可以充分利用会话的结构知识来生成响应。Ubuntu互联网中继聊天（IRC）信道基准测试的实验结果表明，HeterMPC在MPC响应生成方面优于各种基准模型。

### 18. Improving Multi-label Malevolence Detection in Dialogues through Multifaceted Label Correlation Enhancement

**论文题目：**[通过多面标记相关性增强改进对话中的多标记恶意检测](https://aclanthology.org/2022.acl-long.248/)

**论文链接：**https://aclanthology.org/2022.acl-long.248.pdf

**github：**https://github.com/repozhang/MCRf

**摘要：**

如果对话反应是基于负面情绪、不当行为或内容和对话行为方面的不道德价值基础，那么它就是恶意的。对恶意对话反应的检测正在引起越来越多的兴趣。目前关于检测对话恶意的研究在数据集和方法方面存在局限性。首先，与恶意相关的可用对话数据集被标记为单个类别，但在实践中，为每个话语指定一个类别可能并不合适，因为一些恶意话语属于多个标签。第二，当前检测对话恶意忽略标记相关性的方法。因此，我们提出了多标签对话恶意检测的任务，并众包了一个多标签数据集，即多标签对话恶意检测（MDMD）用于评估。我们还提出了一种多标签恶意检测模型，即多面标签相关性增强CRF（MCRF），该模型具有两种标签相关性机制：分类中的标签相关性（LCT）和上下文中的标签相关（LCC）。在MDMD上的实验表明，我们的方法在准确度、召回率、F1和Jaccard得分上分别比最佳基线表现好16.1%、11.9%、12.0%和6.1%。

### 19. Interactive Word Completion for Plains Cree

**论文题目：**[Plains Cree的交互式单词补全](https://aclanthology.org/2022.acl-long.232/)

**论文链接：**https://aclanthology.org/2022.acl-long.232.pdf

**github：**

**摘要：**

在形态复杂的语言中，词形变化丰富的单词的构成对于语言学习者来说是一个挑战。因此，Lane和Bird（2020）提出了一种有限状态方法，将语言中的前置词映射到一组可能的补语，直到下一个语素边界，以逐步构建复杂单词。在这项工作中，我们开发了一种基于Plains Cree（nêhiyawêwin）有限状态形态分析仪的基于形态的自动完成方法，展示了该概念在更大、更完整的形态转换器上的可移植性。此外，我们提出并比较了各种新颖的关于变形自动完成输出的排序策略。最佳加权方案将目标完成率排名在前10位，64.9%的查询结果排名在前50位，73.9%的查询。

### 20. Internet-Augmented Dialogue Generation

**论文题目：**[互联网增强对话生成](https://arxiv.org/abs/2107.07566v1)

**论文链接：**https://arxiv.org/pdf/2107.07566v1.pdf

**ParlAI：**https://parl.ai/projects/sea/

**摘要：**

我们这个星球上最大的不断更新的知识库可以通过互联网搜索访问。在这项工作中，我们研究了如何让会话代理访问这些信息。尽管大型语言模型在其权重范围内存储了大量知识，但在生成对话时会产生幻觉（Shuster等人，2021）；此外，这些事实在模型训练时被及时冻结。相比之下，我们提出了一种方法，即学习根据上下文生成互联网搜索查询，然后对搜索结果进行条件处理，最终生成响应，这种方法可以使用最新的相关信息。我们在一个新收集的人类对话数据集上训练和评估这些模型，其中一位发言者在知识驱动的讨论中可以访问互联网搜索，以便为他们的回答奠定基础。我们发现，与不使用增强或基于FAISS的检索的现有方法相比，基于搜索查询的会话中互联网访问提供了优越的性能（Lewis等人，2020）。

### 21. Knowledge Enhanced Reflection Generation for Counseling Dialogues

**论文题目：**[咨询对话的知识强化反思生成](https://github.com/ICTKC/Papers_DPC/files/8860703/2022.acl-long.221-Knowledge.Enhanced.Reflection.Generation.for.Counseling.Dialogues.pdf)

**论文链接：**https://github.com/ICTKC/Papers_DPC/files/8860703/2022.acl-long.221-Knowledge.Enhanced.Reflection.Generation.for.Counseling.Dialogues.pdf

**github：**

**摘要：**

在本文中，我们研究了常识和领域知识在使用知识整合的检索和生成方法生成咨询对话中的反应时的作用。我们提出了一种通过网络挖掘收集领域知识的管道，并表明从领域特定知识库和常识知识库中检索可以提高生成的响应的质量。我们还提出了一个模型，该模型结合了COMET使用软位置编码和掩蔽自我注意产生的知识。我们表明，检索到的知识和COMET生成的知识都提高了系统的性能，这是通过自动度量和人工评估来衡量的。最后，我们对我们系统编码的知识类型进行了比较研究，结果表明因果关系和意向关系比其他类型的常识关系更有利于生成任务。

### 22. M3ED: Multi-modal Multi-scene Multi-label Emotional Dialogue Database

**论文题目：**[M3ED：多模态多场景多标签的情感对话数据集](https://aclanthology.org/2022.acl-long.391/)

**论文链接：**https://aclanthology.org/2022.acl-long.391.pdf

**github：**https://github.com/AIM3-RUC/RUCM3ED

**摘要：**

说话人的情绪状态会受到对话中许多不同因素的影响，如对话场景、对话主题和对话者刺激。然而，目前可用于支持对话中的这种多模态情感分析的数据资源在规模和多样性方面有限。在这项工作中，我们提出了一个多模式多场景多标签情感对话数据集M3ED，该数据集包含来自56部不同电视剧的990个二元情感对话，总共9082个回合和24449个话语。M3ED在话语层面上有7种情绪类别（快乐、惊讶、悲伤、厌恶、愤怒、恐惧和中性），包括声音、视觉和文本形式。据我们所知，M3ED是第一个中文多模态情感对话数据集。这对于跨文化情感的分析和识别具有重要价值。我们在M3ED数据集上应用了几种最先进的方法来验证数据集的有效性和质量。我们还提出了一个通用的多模态对话感知交互框架MDI，用于为情感识别建模对话上下文，该框架的性能与M3ED上的最先进方法相当。完整的数据集和代码可用。

### 23. MISC: A Mixed Strategy-Aware Model integrating COMET for Emotional Support Conversation

**论文题目：**[MISC：整合COMET的情感支持会话混合策略感知模型](https://arxiv.org/abs/2203.13560)

**论文链接：**https://arxiv.org/pdf/2203.13560.pdf

**github：**https://github.com/morecry/MISC

**摘要：**

将现有的方法应用于情感支持会话（为有需要的人提供有价值的帮助）有两个主要局限：（a）它们通常使用会话级别的情感标签，该标签太粗，无法捕捉用户的即时心理状态；（b） 他们中的大多数关注于在回应中表达同理心，而不是逐渐减少用户的痛苦。为了解决这些问题，我们提出了一种新的MISC模型，该模型首先推断用户的细粒度情感状态，然后使用混合策略巧妙地做出响应。在基准数据集上的实验结果证明了我们方法的有效性，并揭示了细粒度情绪理解和混合策略建模的好处。

### 24. Multi-Party Empathetic Dialogue Generation: A New Task for Dialog Systems

**论文题目：**[多方同理对话生成：对话系统的新任务](https://openreview.net/forum?id=pheR28vOKmF)

**论文链接：**https://openreview.net/pdf?id=pheR28vOKmf

**github：**

**摘要：**

移情对话汇集了情感理解、情感投射和适当的反应生成。现有的同情心对话生成工作集中于双方对话场景。然而，多党对话在现实中无处不在。此外，情感和情感通常是混淆的；为了理解脆弱而微妙的人类情感，需要进行精细的移情分析。我们在本研究中提出了一项新的任务，称为“多党同理对话生成”，以解决这些问题。针对这项任务，相应地提出了一个包含130k多方对话的新数据集MPED，这弥补了该领域缺乏大规模基准的不足。此外，通过探索多方移情对话学习的静态敏感性和动态情感，引入了多方移情会话生成的静态-动态模型SDMPED，作为基线，该模型有助于SDMPED在MPED上实现最先进的表现。

### 25. Multi-Task Pre-Training for Plug-and-Play Task-Oriented Dialogue System

**论文题目：**[面向即插即用任务的对话系统的多任务预训练](https://arxiv.org/abs/2109.14739)

**论文链接：**https://arxiv.org/pdf/2109.14739.pdf

**github：**https://github.com/awslabs/pptod

**摘要：**

经过预先训练的语言模型最近被证明有利于面向任务的对话（TOD）系统。尽管取得了成功，但现有方法通常将此任务表述为级联生成问题，这可能导致不同子任务之间的错误累积和更大的数据注释开销。在本研究中，我们提出了PPTOD，一种面向任务的对话的统一即插即用模型。此外，我们引入了一种新的对话多任务预训练策略，允许模型从异构对话语料库中学习主要的TOD任务完成技能。我们在三个基准TOD任务上广泛测试了我们的模型，包括端到端对话建模、对话状态跟踪和意图分类。实验结果表明，PPTOD在高资源和低资源场景下的所有评估任务上都达到了最新水平。此外，与以前的SOTA方法的比较表明，PPTOD生成的响应在事实上更正确，在语义上更连贯，正如人类注释者所判断的那样。

### 26. Multimodal Dialogue Response Generation

**论文题目：**[多模态对话回复生成](https://aclanthology.org/2022.acl-long.204/)

**论文链接：**https://aclanthology.org/2022.acl-long.204.pdf

**github：**

**摘要：**

图像响应已被认为是智能会话主体的重要能力。然而，现有的研究只集中于探索依赖于基于检索的方法的多模态对话模型，而忽略了生成方法。为了填补空白，我们首先提出了一个新任务：多模态对话响应生成（MDRG）-给定对话历史，一个模型需要生成文本序列或图像作为响应。学习这种MDRG模型通常需要包含难以获得的文本和图像的多模态对话。出于实践中的挑战，我们在一个自然假设下考虑MDRG，即只有有限的培训示例可用。在这样一个低资源环境下，我们设计了一个新的会话代理Diver，以便从整个生成模型中分离依赖于多模态对话的参数。通过这种方法，可以分别从大量纯文本对话和文本图像对中学习模型的主要部分，然后可以使用有限的训练示例很好地拟合整个参数。大量实验表明，我们的方法在自动和人工评估方面都取得了最先进的结果，并且可以生成信息丰富的文本和高分辨率图像响应。

### 27. Online Semantic Parsing for Latency Reduction in Task-Oriented Dialogue

**论文题目：**[基于在线语义分析的任务型对话延迟降低](https://aclanthology.org/2022.acl-long.110.pdf)

**论文链接：**https://aclanthology.org/2022.acl-long.110.pdf

**github：**

**摘要：**

标准会话语义解析将完整的用户话语映射到可执行程序中，然后执行程序以响应用户。当程序包含昂贵的函数调用时，这可能会很慢。我们研究在用户仍在说话时通过预测和执行函数调用来减少延迟的机会。为此，我们引入了在线语义解析的任务，并根据同声机器翻译的启发，提出了一个正式的延迟减少度量。我们提出了一个通用框架，首先是程序预测模块的学习前缀，然后是一个简单而有效的阈值启发式算法，用于早期执行子程序的选择。在SMCalFlow和TreeDST数据集上的实验表明，我们的方法在良好的解析质量下实现了大的延迟减少，根据函数执行时间和允许的成本，延迟减少了30%-63%。

### 28. Other Roles Matter! Enhancing Role-Oriented Dialogue Summarization via Role Interactions

**论文题目：**[其他角色很重要！通过角色互动加强面向角色的对话总结](https://aclanthology.org/2022.acl-long.182/)

**论文链接：**https://aclanthology.org/2022.acl-long.182.pdf

**github：**https://github.com/xiaolinAndy/RODS

**摘要：**

面向角色的对话摘要是为对话中的不同角色生成摘要，例如，商家和消费者。现有方法通过分别总结每个角色的内容来处理此任务，因此容易忽略其他角色的信息。然而，我们认为其他角色的内容可能有助于总结的质量，例如其他角色提到的遗漏信息。因此，我们提出了一种新的面向角色的对话摘要角色交互增强方法。它采用交叉注意和解码器自我注意交互，以交互方式获取其他角色的关键信息。交叉注意交互旨在选择其他角色的关键对话话语，而解码器自我注意交互旨在从其他角色的摘要中获取关键信息。实验结果表明，我们提出的方法在两个面向公共角色的对话摘要数据集上明显优于强基线。广泛的分析表明，其他角色的内容可以帮助生成具有更完整语义和正确主题结构的摘要。

### 29. ProphetChat: Enhancing Dialogue Generation with Simulation of Future Conversation

-  **论文题目：**[ProphetChat：通过模拟未来对话来增强对话生成](https://arxiv.org/abs/2203.08979)

-  **论文链接：**https://aclanthology.org/2022.acl-long.68.pdf

-  **github：**未开源

-  **https://github.com/microsoft/DialoGPT** 

-  **https://github.com/li3cmz/GRADE** 

-  **摘要：**

-  典型的生成对话模型利用对话历史来生成响应。然而，由于一个对话话语通常可以通过多个不同的响应来适当地回答，因此仅基于历史信息生成所需的响应并不容易。直观地说，如果聊天机器人能够提前预见到用户在收到响应后会谈论什么（即对话未来），它可能会提供更多信息量的响应。因此，我们提出了一个名为 ProphetChat 的新型对话生成框架，该框架利用推理阶段的模拟对话期货来增强响应生成。为了使聊天机器人能够预见对话的未来，我们使用典型的对话生成模型和对话选择器为对话未来模拟设计了一种类似光束搜索的推出策略。通过模拟的期货，我们然后利用历史响应生成器和未来响应生成器的集合来共同生成信息量更大的响应。对两个流行的开放域对话数据集的实验表明，ProphetChat 可以在强基线上产生更好的响应，这验证了结合模拟对话期货的优势。

### 30. QAConv: Question Answering on Informative Conversations

-  **论文题目：**[Qaconv：关于信息对话的问答](https://arxiv.org/abs/2203.08979)

-  **论文链接：**https://arxiv.org/pdf/2105.06912.pdf

-  **github：**https://github.com/salesforce/QAConv 

-  **摘要：**

-  本文介绍了 QAConv，这是一个新的问答 (QA) 数据集，它使用对话作为知识源。我们专注于内容丰富的对话，包括商务电子邮件、小组讨论和工作渠道。与开放领域和面向任务的对话不同，这些对话通常是冗长的、复杂的、异步的，并且涉及强大的领域知识。总的来说，我们从 10,259 个选定的对话中收集了 34,608 个 QA 对，其中既有人工编写的问题，也有机器生成的问题。我们使用问题生成器和对话摘要器作为辅助工具来收集和推荐问题。数据集有两种测试场景：块模式和完整模式，取决于是否提供或检索了接地的部分对话。实验结果表明，最先进的预训练 QA 系统的零样本性能有限，并且倾向于将我们的问题预测为无法回答。我们的数据集提供了一个新的培训和评估测试平台，以促进对话研究的 QA。

### 31. SaFeRDialogues: Taking Feedback Gracefully after Conversational Safety Failures

-  **论文题目：**[Saferdialogues :在会话安全失败后优雅地接受反馈](https://arxiv.org/abs/2203.08979)

-  **论文链接：**https://arxiv.org/pdf/2110.07518.pdf

-  **github：**https://github.com/facebookresearch/ParlAI/tree/main/parlai/tasks/saferdialogues

-  **摘要：**

-  当前的开放域会话模型很容易以不适当的方式进行交谈。从对话伙伴提供的对话反馈中进行在线学习是模型改进和适应的有希望的途径，以减少这些安全故障的产生。然而，当前最先进的模型倾向于对反馈做出防御性或无意识的反应。这会带来不愉快的体验，并且可能会阻止对话伙伴在未来提供反馈。这项工作提出了 SaFeRDialogues，这是一个对有关安全故障的对话反馈的优雅响应的任务和数据集。我们收集了一个包含 10k 个对话的数据集，其中展示了安全故障、反馈信号以及确认反馈的响应。

### 32. SafetyKit: First Aid for Measuring Safety in Open-domain Conversational Systems

-  **论文题目：**[Safetykit：在开放域对话系统中测量安全性的急救措施](https://arxiv.org/abs/2203.08979)

-  **论文链接：**https://aclanthology.org/2022.acl-long.284.pdf

-  **github：**https://parl.ai/projects/safety_bench/.

-  **摘要：**

-  自然语言处理及其应用的社会影响越来越受到关注。在这份立场文件中，我们关注端到端对话式 AI 的安全问题。我们调查了其中的问题格局，引入了三种观察到的现象的分类法：Instigator、Yea-Sayer 和 Impostor 效应。然后，我们凭经验评估当前工具可以测量这些影响的程度以及当前系统显示它们的程度。我们将这些工具作为“急救箱”（SafetyKit）的一部分发布，以快速评估明显的安全问题。我们的结果表明，虽然当前的工具能够提供对各种环境下系统相对安全性的估计，但它们仍然存在一些缺点。我们提出了几个未来的方向并讨论了道德方面的考虑。

### 33. SalesBot: Transitioning from Chit-Chat to Task-Oriented Dialogues

-  **论文题目：**[SalesBot：从闲聊过渡到面向任务的对话](https://arxiv.org/abs/2203.08979)

-  **论文链接：**https://arxiv.org/pdf/2204.10591.pdf

-  **github：** https://github.com/MiuLab/SalesBot.

-  **摘要：**

-  对话系统通常分为两种类型，开放域和任务导向。第一个侧重于与用户聊天并让他们参与对话，其中选择适合对话上下文的适当主题对于成功对话至关重要。另一个专注于特定的任务而不是随意的谈话，例如，周五晚上找一部电影，或者播放一首歌。这两个方向由于目的不同而分别进行了研究。然而，如何顺利地从社交聊天过渡到任务型对话对于触发商机很重要，并且没有针对此类场景的公开数据。因此，本文重点研究从开放域社交聊天开始的对话，然后逐渐过渡到面向任务的目的，并发布带有详细注释的大规模数据集，以鼓励这一研究方向。为了实现这一目标，本文提出了一个无需人工参与即可自动生成许多对话的框架，其中可以轻松利用任何强大的开放域对话生成模型。人工评估表明，我们生成的对话数据具有合理质量的自然流动，表明我们发布的数据具有指导未来研究方向和商业活动的巨大潜力。此外，发布的模型允许研究人员在目标场景中自动生成无限对话，这可以极大地有利于半监督和无监督方法。本文提出了一个无需人工参与即可自动生成许多对话的框架，其中可以轻松利用任何强大的开放域对话生成模型。人工评估表明，我们生成的对话数据具有合理质量的自然流动，表明我们发布的数据具有指导未来研究方向和商业活动的巨大潜力。此外，发布的模型允许研究人员在目标场景中自动生成无限对话，这可以极大地有利于半监督和无监督方法。本文提出了一个无需人工参与即可自动生成许多对话的框架，其中可以轻松利用任何强大的开放域对话生成模型。人工评估表明，我们生成的对话数据具有合理质量的自然流动，表明我们发布的数据具有指导未来研究方向和商业活动的巨大潜力。此外，发布的模型允许研究人员在目标场景中自动生成无限对话，这可以极大地有利于半监督和无监督方法。人工评估表明，我们生成的对话数据具有合理质量的自然流动，表明我们发布的数据具有指导未来研究方向和商业活动的巨大潜力。此外，发布的模型允许研究人员在目标场景中自动生成无限对话，这可以极大地有利于半监督和无监督方法。人工评估表明，我们生成的对话数据具有合理质量的自然流动，表明我们发布的数据具有指导未来研究方向和商业活动的巨大潜力。此外，发布的模型允许研究人员在目标场景中自动生成无限对话，这可以极大地有利于半监督和无监督方法。

### 34. Should a Chatbot be Sarcastic? Understanding User Preferences Towards Sarcasm Generation

-  **论文题目：**[聊天机器人应该讽刺吗？了解用户对讽刺生成的偏好](https://arxiv.org/abs/2203.08979)

-  **论文链接：**https://aclanthology.org/2022.acl-long.530.pdf

-  **github：**https://github.com/tuhinjubcse/SarcasmGenerationACL2020

-  **https://prolific.co** 

-  **摘要：**

-  以前的讽刺生成研究主要集中在如何生成人们认为具有讽刺意味的文本，以创建更像人类的交互。在本文中，我们认为我们应该首先将注意力转向何时应该产生讽刺的问题，发现人类认为讽刺反应不适合许多输入话语。接下来，我们使用理论驱动的框架来生成讽刺回应，这使我们能够控制生成过程中包含的语言设备。对于每种设备，我们调查了人类将其与讽刺联系起来的程度，发现务实的不真诚和情感标记是使讽刺可识别的关键设备。

### 35. Situated Dialogue Learning through Procedural Environment Generation

-  **论文题目：**[通过程序环境生成进行情境对话学习](https://arxiv.org/abs/2203.08979)

-  **论文链接：**https://arxiv.org/pdf/2110.03262.pdf

-  **github：**https://parl.ai/projects/light

-  **摘要：**

-  我们通过对生成的课程进行培训，教目标驱动的代理在情境环境中进行交互行动和说话。我们的代理在 LIGHT（Urbanek 等人，2019 年）中运作——这是一种大型众包幻想文本冒险游戏，其中代理通过文本自然语言感知世界并与世界互动。这种环境中的目标采取基于角色的任务的形式，包括角色和动机。我们通过学习以程序方式生成额外的新颖文本世界和任务来增强 LIGHT，以创建一个难度稳步增加的课程，以训练智能体实现这些目标。特别是，我们根据原始训练分布中任务的稀有性来衡量课程难度——更容易的环境是更有可能在未增强的数据集中找到的环境。

### 36. Structural Characterization for Dialogue Disentanglement

-  **论文题目：**[对话解纠缠的结构表征](https://aclanthology.org/2022.acl-long.23/)

-  **论文链接：**https://aclanthology.org/2022.acl-long.23.pdf

-  **github：**https://github.com/xbmxb/StructureCharacterization4DD 

-  **摘要：**

-  纠结的多方对话上下文给对话阅读理解带来了挑战，多个对话线程在一个共同的对话记录中同时流动，增加了人类和机器理解对话历史的难度。以往的研究主要集中在具有精心设计的特征的话语编码方法上，但对对话结构的特征特征关注不足。我们特别考虑结构因素，设计了一种新颖的对话解开模型。基于对话是在说话者之间的连续参与和交互上构建的这一事实，我们在两个方面对对话的结构信息进行建模：1）指示消息来自谁的说话者属性，以及 2）显示消息可能引用谁的引用依赖性至。

### 37. The AI Doctor Is In: A Survey of Task-Oriented Dialogue Systems for Healthcare Applications

-  **论文题目：**[人工智能医生在：针对医疗保健应用的面向任务的对话系统的调查](https://arxiv.org/abs/2203.08979)

-  **论文链接：**https://aclanthology.org/2022.acl-long.458.pdf

-  **github：**

-  **摘要：**

-  面向任务的对话系统在医疗保健环境中越来越普遍，并且具有多种架构和目标的特点。尽管这些系统已经在医学界从非技术角度进行了调查，但迄今为止，从严格的计算角度进行的系统评价仍然明显缺失。因此，面向医疗保健的对话系统的许多重要实施细节仍然有限或未明确，从而减缓了该领域的创新步伐。为了填补这一空白，我们调查了来自著名计算机科学、自然语言处理和人工智能领域的 4070 篇论文的初始池，确定了 70 篇讨论面向医疗保健应用的面向任务的对话系统的系统级实现的论文。

### 38. There Are a Thousand Hamlets in a Thousand People’s Eyes: Enhancing Knowledge-grounded Dialogue with Personal Memory

-  **论文题目：**[一千个人眼中有一千个哈姆雷特：用个人记忆增强知识对话](https://arxiv.org/abs/2203.08979)

-  **论文链接：**https://arxiv.org/pdf/2204.02624.pdf

-  **github：**https://github.com/Lucasftc/PersonaKGC

-  **摘要：**

-  基于知识的对话 (KGC) 在构建引人入胜且知识渊博的聊天机器人方面显示出巨大潜力，而知识选择是其中的关键因素。然而，以往的知识选择方法只关注知识与对话上下文之间的相关性，而忽略了对话者的年龄、爱好、教育和生活经历对其个人偏好相对于外部知识有重大影响这一事实。如果不考虑个性化问题，就很难选择合适的知识并产生与角色一致的响应。在这项工作中，我们将个人记忆引入 KGC 的知识选择中，以解决个性化问题。我们提出了一种变分方法来模拟个人记忆与其知识选择之间的潜在关系，并设计一个学习方案，其中从个人记忆到知识的正向映射及其逆向映射包含在一个闭环中，以便他们可以互相教授。实验结果表明，我们的方法在自动评估和人工评估方面都显著优于现有的 KGC 方法。

### 39. Think Before You Speak: Explicitly Generating Implicit Commonsense Knowledge for Response Generation

-  **论文题目：**[三思而后行：为响应生成显式生成隐式常识知识](https://arxiv.org/abs/2203.08979)

-  **论文链接：**https://aclanthology.org/2022.acl-long.88.pdf

-  **github：**

-  **摘要：**

-  我们提出了一个完整的管道来提取小说中的人物并将它们链接到他们的直接言语话语。我们的模型分为三个独立的组件：提取直接语音，编译字符列表，并将这些字符归因于他们的话语。尽管我们发现现有系统可以准确地执行前两个任务，但由于叙述者缺乏明确的字符提及，以及在此类明确提及时经常使用名词和代词共指，将字符归因于直接语音是一个具有挑战性的问题。我们调整对话状态跟踪所取得的进展来解决一个新问题：将发言者归因于对话。这是深度学习在说话人归因中的首次应用，它表明可以克服过去使用的手工制作的功能和规则的需求。我们的完整管道在 F1 分数中将最先进模型的性能提高了 50%。

### 40. UniTranSeR: A Unified Transformer Semantic Representation Framework for Multimodal Task-Oriented Dialog System

-  **论文题目：**[UniTranSeR：用于多模式面向任务的对话系统的统一Transformer 语义表示框架](https://aclanthology.org/2022.acl-long.9/)

-  **论文链接：**https://aclanthology.org/2022.acl-long.9.pdf

-  **github：**

-  **摘要：**

-  多模态任务导向对话系统作为一种更自然、更智能的交互方式，近年来受到了广泛关注，并取得了许多令人瞩目的进展。然而，几乎所有现有的研究都遵循管道，首先分别学习模态内特征，然后进行简单的特征连接或基于注意力的特征融合以生成响应，这阻碍了他们学习模态间交互和进行跨模态特征对齐产生更多的意图感知反应。为了解决这些问题，我们提出了 UniTranSeR，这是一个统一的 Transformer 语义表示框架，具有用于多模式对话系统的特征对齐和意图推理。具体来说，我们首先将多模态特征嵌入到统一的 Transformer 语义空间中，以促进模态间交互，然后设计一个特征对齐和意图推理（FAIR）层来执行跨模态实体对齐和细粒度的键值推理，从而有效地识别用户的意图以产生更准确的响应。实验结果验证了 UniTranSeR 的有效性，表明它在代表性 MMD 数据集上明显优于最先进的方法。

### 41. What does the sea say to the shore? A BERT based DST style approach for speaker to dialogue attribution in novels

-  **论文题目：**[海对岸说什么？一种基于 BERT 的 DST 风格方法，用于小说中的演讲者对话归因](https://arxiv.org/abs/2203.08979)

-  **论文链接：**https://aclanthology.org/2022.acl-long.400.pdf

-  **github：**

-  **摘要：**

-  我们提出了一个完整的管道来提取小说中的人物并将它们链接到他们的直接言语话语。我们的模型分为三个独立的组件：提取直接语音，编译字符列表，并将这些字符归因于他们的话语。尽管我们发现现有系统可以准确地执行前两个任务，但由于叙述者缺乏明确的字符提及，以及在此类明确提及时经常使用名词和代词共指，将字符归因于直接语音是一个具有挑战性的问题。我们调整对话状态跟踪所取得的进展来解决一个新问题：将发言者归因于对话。这是深度学习在说话人归因中的首次应用，它表明可以克服过去使用的手工制作的功能和规则的需求。我们的完整管道在 F1 分数中将最先进模型的性能提高了 50%。

### 42. Where to Go for the Holidays: Towards Mixed-Type Dialogs for Clarification of User Goals

-  **论文题目：**[去哪里度假：迈向混合类型对话框以澄清用户目标](https://arxiv.org/abs/2203.08979)

-  **论文链接：**https://arxiv.org/pdf/2204.07299.pdf

-  **github：**https://github.com/PaddlePaddle/Research/tree/master/NLP

-  **摘要：**

-  大多数对话系统假定用户在开始交互之前已经确定了明确而具体的目标。例如，用户已经确定了预订航班的出发地、目的地和旅行时间。然而，在许多情况下，受经验和知识的限制，用户可能知道他们需要什么，但仍然很难通过确定所有必要的插槽来找出明确而具体的目标。 在本文中，我们确定了这一挑战，并通过收集新的人对人混合类型对话语料库向前迈进了一步。它包含 4 种对话类型和 5 个域的 5k 对话会话和 168k 话语。在每个会话中，代理首先提供与用户目标相关的知识，以帮助确定明确和具体的目标，然后帮助实现它们。 此外，我们提出了一种混合型对话模型，该模型具有一种新颖的基于提示的持续学习机制。具体来说，该机制使模型能够通过有效地利用现有的对话语料库来不断增强其在任何特定类型上的能力。

### 43. Speaker Information Can Guide Models to Better Inductive Biases: A Case Study On Predicting Code-Switching

-  **论文题目：**[演讲者信息可以引导模型更好地归纳偏差：预测代码转换的案例研究](https://arxiv.org/abs/2203.08979)

-  **论文链接：**https://arxiv.org/pdf/2203.08979.pdf

-  **github：**https://github.com/ostapen/Switch-and-Explain

-  **摘要：**

-  在人们生成的数据上训练的自然语言处理 (NLP) 模型可能不可靠，因为在没有任何限制的情况下，它们可以从与任务无关的虚假相关性中学习。我们假设，以受控的、受过教育的方式用说话者信息丰富模型可以引导他们发现相关的归纳偏差。对于预测英语-西班牙语双语对话中的语码转换点的说话人驱动任务，我们表明，添加基于社会语言学的说话人特征作为前置提示可以显着提高准确性。我们发现，通过在输入中添加有影响力的短语，说话者知情模型可以学习有用且可解释的语言信息。据我们所知，我们是第一个将说话人特征纳入语码转换神经模型的人。
